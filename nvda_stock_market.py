# -*- coding: utf-8 -*-
"""NVDA_Stock_Market.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iF5MDsJk-YAz0zkvyHKyDIEiemy6ERKM
"""

# General Imports
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import LSTM, SimpleRNN, Dense
from datetime import datetime
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from keras.utils import plot_model
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.tsa.seasonal import seasonal_decompose

# Creating a Ticker object for NVIDIA stock with symbol "NVDA"
ticker = 'NVDA'
df = yf.download(ticker, start="2017-01-01", end="2023-12-14")
df

# Resample data to business days,filling missing values with previous day
data = df[['Close']].asfreq('B').fillna(method='ffill')
# Resetting the index of the dataframe
data = data.reset_index()

# Plotting closing prices over time
plt.figure(figsize=(14, 5))
plt.plot(data['Date'], data['Close'], label='Closing Price')
plt.title('Closing Prices Over Time')
plt.xlabel('Date')
plt.ylabel('Closing Price')
plt.legend()
plt.savefig('figure1.png')
plt.show()

# Decomposing time series for seasonality check
result = seasonal_decompose(df['Close'], model='additive', period=1)
result.plot()
plt.title('Seasonal Decomposition of Close Prices')
plt.xlabel('Date')
plt.ylabel('Value')
plt.savefig('figure2.png')
plt.show()

# Plot autocorrelation function for Close data
plot_acf(df['Close'], lags = 50)
plt.title('Autocorrelation Function for Close Prices')
plt.xlabel('Lags')
plt.ylabel('Autocorrelation')
plt.savefig('figure3.png')
plt.show()

# Calculate rolling 63 day annualized volatility for Close as total traiding days in a year is 252
roll_vol = df['Close'].rolling(63).std() * np.sqrt(252)
# Plotting rolling volatility
plt.plot(roll_vol, label='Rolling Volatility (63 days)')
plt.title('Rolling 63-Day Annualized Volatility for Close Prices')
plt.xlabel('Date')
plt.ylabel('Volatility')
plt.legend()
plt.savefig('roll_vol_plot.png')
plt.show()

# Perform Augmented Dickey-Fuller test on Close data
result = adfuller(df['Close'])
print('ADF Statistic:', result[0]) # Print ADF Statistic
print('p-value:', result[1]) # Print p-value
print('Critical Values:', result[4]) # Print Critical Values

# Scale Close data with MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df['Close'].values.reshape(-1,1))
# Defining look-back period and split data into train/test data
look_back = 80
train_size = int(len(scaled_data) * 0.80)
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size - look_back:]
# Creating time series generatord for training and testing data
train_generator = TimeseriesGenerator(train_data, train_data,
                                     length=look_back, batch_size=20)
test_generator = TimeseriesGenerator(test_data, test_data,
                                     length=look_back, batch_size=1)

# Defining LSTM model architecture
lstm_model = Sequential()
# Add LSTM layer with 100 units
lstm_model.add(LSTM(units=100, return_sequences=True,
                    input_shape=(look_back, 1)))
# Add dropout regularization
lstm_model.add(Dropout(0.2))
# Add LSTM layer with 100 units
lstm_model.add(LSTM(units=100,return_sequences = True))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(units=100))
lstm_model.add(Dropout(0.2))
# Add Dense output layer with 1 unit
lstm_model.add(Dense(1))
# Compile model using Adam optimizer and MSE loss
lstm_model.compile(optimizer='adam', loss='mean_squared_error')
lstm_model.fit(train_generator, epochs=61 )

# Visualizing architecture of LSTM model using plot_model function
plot_model(lstm_model)

# Generating predictions on test data using LSTM model
lstm_predictions = lstm_model.predict(test_generator)
# Rescaling LSTM predictions to original values
lstm_predictions = scaler.inverse_transform(lstm_predictions)
# Converting portion of test data back to its original scale
actual_prices = scaler.inverse_transform(test_data[look_back:])

# Calculating lengths of actual and predicted price arrays
length_actual = len(actual_prices)
length_predicted = len(lstm_predictions)

print("Length of Actual Monthly Return:", length_actual)
print("Length of Predicted Monthly Return:", length_predicted)

# Calculating Mean Squared Error, Mean Absolute Error and R-squared
mse = mean_squared_error(actual_prices, lstm_predictions)
mae = mean_absolute_error(actual_prices, lstm_predictions)
r2 = r2_score(actual_prices, lstm_predictions)

print("Mean Squared Error (MSE):", mse)
print("Mean Absolute Error (MAE):", mae)
print("R-squared (R2):", r2)

# Calculating Root Mean Squared Error
rmse = np.sqrt(np.mean(lstm_predictions - actual_prices) ** 2)
print("Root Mean Squared Error :", rmse)

# Calculating Mean Absolute Percentage Error
mape = np.mean(np.abs((actual_prices - lstm_predictions) / actual_prices)) * 100
# Computing predictions within 1% range of actual prices
within_1_percent = np.sum(np.abs((actual_prices - lstm_predictions) / actual_prices) <= 0.01) / len(actual_prices) * 100

print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")
print(f"Percentage of Predictions Within 1% Range: {within_1_percent:.2f}%")

# Visualizing actual and predicted Nvidia stock prices using LSTM
plt.figure(figsize=(15,5))
plt.plot(actual_prices, color='red', label='Nvidia Stock Price with LSTM')
plt.plot(lstm_predictions, color='green', label='Predicted Nvidia Stock Price with LSTM')
plt.title('Nvidia Stock Price Prediction')
plt.xlabel('Date')
plt.ylabel('Nvidia Stock Price')
plt.legend()
plt.grid(True)
plt.savefig('figure Prediction.png')
plt.show()

def predict_future_days(model, base_data, days_to_predict, scaler, look_back=2000):
    # Start with the last days of the base data
    input_data = base_data[-look_back:].reshape(1, look_back, 1)

    # Predict future days
    future_predictions = []

    for _ in range(days_to_predict):
        # Make a prediction
        prediction = model.predict(input_data)

        # Append the prediction
        future_predictions.append(prediction[0, 0])

        # Update the input data to include the prediction and exclude the oldest data point
        # Correctly reshape the prediction to (1, 1, 1) before appending
        input_data = np.append(input_data[:, 1:, :], prediction.reshape(1, 1, 1), axis=1)

    # Invert the scaling
    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))

    return future_predictions

# Predicting Nvidia stock prices for next 180 days using LSTM
days_to_predict = 180
future_days = predict_future_days(lstm_model, scaled_data, days_to_predict, scaler, look_back)

print(future_days)

# Plotting historical and predicted Nvidia stock prices
predicted_dates = pd.date_range(start=df.index[-1], periods=days_to_predict + 1, closed='right')
plt.figure(figsize=(15,5))
plt.plot(df.index, df['Close'], color='blue', label='Historical Daily Closing Price')
plt.plot(predicted_dates, future_days, color='red', label='Predicted Future Price',linestyle='dashed')
plt.title(f'Nvidia Stock Price Prediction for the Next {days_to_predict} Days')
plt.xlabel('Time')
plt.ylabel('Nvidia Stock Price')
plt.legend()
plt.grid(True)
plt.savefig('Future Prediction.png')
plt.show()